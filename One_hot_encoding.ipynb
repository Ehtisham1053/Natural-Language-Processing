{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0SZryXnERSeIAgmRDeySC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ehtisham1053/Natural-Language-Processing/blob/main/One_hot_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-Hot Encoding in NLP\n",
        "One-hot encoding is a technique used in Natural Language Processing (NLP) to represent words or characters as binary vectors. Each unique word in the vocabulary is assigned a unique vector where only one position is 1, and all others are 0.\n",
        "\n",
        "##Steps to Implement One-Hot Encoding\n",
        "* Create a sample text corpus\n",
        "* Tokenize the sentences into words\n",
        "* Build a vocabulary\n",
        "* Generate one-hot encoded vectors for each word\n"
      ],
      "metadata": {
        "id": "KKxGBPmFWX0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JMfGUL_vWLne"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define a Sample Corpus"
      ],
      "metadata": {
        "id": "4MOlGhBFWjnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"I love NLP\", \"NLP is amazing\", \"I love deep learning\"]"
      ],
      "metadata": {
        "id": "_4KW3vOzWgsR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 3: Tokenize the Corpus and Create Vocabulary"
      ],
      "metadata": {
        "id": "B0wutRqiW2zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = set(word for sentence in corpus for word in sentence.split())\n",
        "vocab = list(words)\n",
        "\n",
        "print(\"Vocabulary:\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNQst14zWmTd",
        "outputId": "e3a5ca78-97b4-43fd-baf7-3f4c53912efa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['I', 'learning', 'love', 'NLP', 'amazing', 'is', 'deep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total vocabulary size = 7 unique words."
      ],
      "metadata": {
        "id": "rCW2NTxsYAWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Create Word-to-Index Mapping"
      ],
      "metadata": {
        "id": "feLWKR-UYEuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign an index to each word\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "print(\"Word Index Mapping:\", word_to_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUCvUZoW75F",
        "outputId": "e5d23bb2-d57a-47a5-b977-0af7ed6ddffe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index Mapping: {'I': 0, 'learning': 1, 'love': 2, 'NLP': 3, 'amazing': 4, 'is': 5, 'deep': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Explanation:\n",
        "\n",
        "* We create a dictionary where each word gets a unique index."
      ],
      "metadata": {
        "id": "eAWnPFDXYK27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Perform One-Hot Encoding"
      ],
      "metadata": {
        "id": "1rDSK4_wYOvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "integer_encoded = np.array([[word_to_index[word]] for word in vocab])\n",
        "one_hot_encoded = encoder.fit_transform(integer_encoded)\n",
        "\n",
        "for word, vector in zip(vocab, one_hot_encoded):\n",
        "    print(f\"{word}: {vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coi3U2iTYHAk",
        "outputId": "7ed540d6-37b7-447f-ef3d-d1ce99d1a0d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: [1. 0. 0. 0. 0. 0. 0.]\n",
            "learning: [0. 1. 0. 0. 0. 0. 0.]\n",
            "love: [0. 0. 1. 0. 0. 0. 0.]\n",
            "NLP: [0. 0. 0. 1. 0. 0. 0.]\n",
            "amazing: [0. 0. 0. 0. 1. 0. 0.]\n",
            "is: [0. 0. 0. 0. 0. 1. 0.]\n",
            "deep: [0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step\tAction\n",
        "* 1Ô∏è‚É£\tDefine a sample corpus\n",
        "* 2Ô∏è‚É£\tTokenize the sentences into words\n",
        "* 3Ô∏è‚É£\tCreate a vocabulary of unique words\n",
        "* 4Ô∏è‚É£\tAssign indices to words\n",
        "* 5Ô∏è‚É£\tConvert words into one-hot encoded vectors"
      ],
      "metadata": {
        "id": "PppAQVm3Ybi-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ve1x2_smYUgY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}